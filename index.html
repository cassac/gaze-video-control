<html>

<head>
    <meta charset="utf-8">
    <meta http-equiv="Cache-control" content="no-cache, no-store, must-revalidate">
    <meta http-equiv="Pragma" content="no-cache">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <title>Face Landmarker</title>
    <style>
        @use "@material";

        body {
            font-family: helvetica, arial, sans-serif;
            margin: 2em;
            color: #3d3d3d;
            --mdc-theme-primary: #007f8b;
            --mdc-theme-on-primary: #f1f3f4;
        }

        h1 {
            font-style: italic;
            color: #ff6f00;
            color: #007f8b;
        }

        h2 {
            clear: both;
        }

        em {
            font-weight: bold;
        }

        video {
            clear: both;
            display: block;
            transform: rotateY(180deg);
            -webkit-transform: rotateY(180deg);
            -moz-transform: rotateY(180deg);
        }

        section {
            opacity: 1;
            transition: opacity 500ms ease-in-out;
        }

        header,
        footer {
            clear: both;
        }

        .removed {
            display: none;
        }

        .invisible {
            opacity: 0.2;
        }

        .note {
            font-style: italic;
            font-size: 130%;
        }

        .videoView,
        .detectOnClick,
        .blend-shapes {
            position: relative;
            float: left;
            width: 48%;
            margin: 2% 1%;
            cursor: pointer;
        }

        .videoView p,
        .detectOnClick p {
            position: absolute;
            padding: 5px;
            background-color: #007f8b;
            color: #fff;
            border: 1px dashed rgba(255, 255, 255, 0.7);
            z-index: 2;
            font-size: 12px;
            margin: 0;
        }

        .highlighter {
            background: rgba(0, 255, 0, 0.25);
            border: 1px dashed #fff;
            z-index: 1;
            position: absolute;
        }

        .canvas {
            z-index: 1;
            position: absolute;
            pointer-events: none;
        }

        .output_canvas {
            transform: rotateY(180deg);
            -webkit-transform: rotateY(180deg);
            -moz-transform: rotateY(180deg);
        }

        .detectOnClick {
            z-index: 0;
        }

        .detectOnClick img {
            width: 100%;
        }

        .blend-shapes-item {
            display: flex;
            align-items: center;
            height: 20px;
        }

        .blend-shapes-label {
            display: flex;
            width: 120px;
            justify-content: flex-end;
            align-items: center;
            margin-right: 4px;
        }

        .blend-shapes-value {
            display: flex;
            height: 16px;
            align-items: center;
            background-color: #007f8b;
        }

        #iframe-container {
            text-align: center;
        }
    </style>
    <link href="https://unpkg.com/material-components-web@latest/dist/material-components-web.min.css" rel="stylesheet">
    <script src="https://unpkg.com/material-components-web@latest/dist/material-components-web.min.js"></script>
</head>

<body>
    <div id="iframe-container">

        <iframe id="existing-iframe-example" width="640" height="360"
            src="https://www.youtube.com/embed/M7lc1UVf-VE?enablejsapi=1" frameborder="0"
            style="border: solid 4px #37474F"></iframe>
    </div>

    <section id="demos" class="invisible">
        <div id="liveView" class="videoView">
            <button id="webcamButton" class="mdc-button mdc-button--raised">
                <span class="mdc-button__ripple"></span>
                <span class="mdc-button__label">ENABLE WEBCAM</span>
            </button>
            <div style="position: relative;">
                <video id="webcam" style="position: abso" autoplay playsinline></video>
                <canvas class="output_canvas" id="output_canvas"
                    style="position: absolute; left: 0px; top: 0px;"></canvas>
                    <p id='gesture_output' class="output">
            </div>
        </div>
        <div class="blend-shapes">
            <ul class="blend-shapes-list" id="video-blend-shapes"></ul>
        </div>
        <p>Hold your face in front of your webcam to get real-time face landmarker detection.</br>Click <b>enable
                webcam</b> below and grant access to the webcam if prompted.</p>
    </section>
    <script>
        var tag = document.createElement('script');
        tag.id = 'iframe-demo';
        tag.src = 'https://www.youtube.com/iframe_api';
        var firstScriptTag = document.getElementsByTagName('script')[0];
        firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

        var player;
        function onYouTubeIframeAPIReady() {
            player = new YT.Player('existing-iframe-example', {
                events: {
                    'onReady': onPlayerReady,
                    'onStateChange': onPlayerStateChange
                }
            });
        }
        function onPlayerReady(event) {
            console.log('ready')
            document.getElementById('existing-iframe-example').style.borderColor = '#FF6D00';
        }
        function changeBorderColor(playerStatus) {
            var color;
            if (playerStatus == -1) {
                color = "#37474F"; // unstarted = gray
            } else if (playerStatus == 0) {
                color = "#FFFF00"; // ended = yellow
            } else if (playerStatus == 1) {
                color = "#33691E"; // playing = green
            } else if (playerStatus == 2) {
                color = "#DD2C00"; // paused = red
            } else if (playerStatus == 3) {
                color = "#AA00FF"; // buffering = purple
            } else if (playerStatus == 5) {
                color = "#FF6DOO"; // video cued = orange
            }
            if (color) {
                document.getElementById('existing-iframe-example').style.borderColor = color;
            }
        }
        function onPlayerStateChange(event) {
            console.log('statechange')
            if (!window.userHasInteractedWithVideo && event.data == YT.PlayerState.PLAYING) {
                window.userHasInteractedWithVideo = true
            }
            changeBorderColor(event.data);
        }
        window.player = player;
    </script>
    <script type="module">
        // gaze module
        import vision from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3";
        const { GestureRecognizer, FaceLandmarker, FilesetResolver, DrawingUtils, FaceDetector, Detection } = vision;
        const demosSection = document.getElementById("demos");
        const imageBlendShapes = document.getElementById("image-blend-shapes");
        const videoBlendShapes = document.getElementById("video-blend-shapes");
        const PLAYBACK_THRESHOLD = 0.35
        const TARGET_ATTRIBUTES = new Set(
            ['eyeLookDownLeft',
                'eyeLookDownRight',
                'eyeLookInLeft',
                'eyeLookInRight',
                'eyeLookOutLeft',
                'eyeLookOutRight',
                'eyeLookUpLeft',
                'eyeLookUpRight'
            ])

            let gestureRecognizer;
        let userHasInteractedWithVideo = false
        let faceLandmarker;
        let runningMode = "VIDEO";
        let enableWebcamButton;
        let webcamRunning = false;
        const videoWidth = 480;

        // Before we can use HandLandmarker class we must wait for it to finish
        // loading. Machine Learning models can be large and take a moment to
        // get everything needed to run.
        async function createFaceLandmarker() {
            const filesetResolver = await FilesetResolver.forVisionTasks(
                "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm"
            );
            faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {
                baseOptions: {
                    modelAssetPath: `https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`,
                    delegate: "GPU"
                },
                outputFaceBlendshapes: true,
                runningMode,
                numFaces: 1
            });
            demosSection.classList.remove("invisible");
        }
        createFaceLandmarker();
        const createGestureRecognizer = async () => {
            const vision = await FilesetResolver.forVisionTasks("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm");
            gestureRecognizer = await GestureRecognizer.createFromOptions(vision, {
                baseOptions: {
                    modelAssetPath: "https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task",
                    delegate: "GPU"
                },
                runningMode: runningMode
            });
            demosSection.classList.remove("invisible");
        };
        createGestureRecognizer();

        /********************************************************************
        // Demo 1: Grab a bunch of images from the page and detection them
        // upon click.
        ********************************************************************/

        // In this demo, we have put all our clickable images in divs with the
        // CSS class 'detectionOnClick'. Lets get all the elements that have
        // this class.
        const imageContainers = document.getElementsByClassName("detectOnClick");

        // Now let's go through all of these and add a click event listener.
        for (let imageContainer of imageContainers) {
            // Add event listener to the child element whichis the img element.
            imageContainer.children[0].addEventListener("click", handleClick);
        }

        // When an image is clicked, let's detect it and display results!
        async function handleClick(event) {
            if (!faceLandmarker) {
                console.log("Wait for faceLandmarker to load before clicking!");
                return;
            }

            if (runningMode === "VIDEO") {
                runningMode = "IMAGE";
                await faceLandmarker.setOptions({ runningMode });
            }
            // Remove all landmarks drawed before
            const allCanvas = event.target.parentNode.getElementsByClassName("canvas");
            for (var i = allCanvas.length - 1; i >= 0; i--) {
                const n = allCanvas[i];
                n.parentNode.removeChild(n);
            }

            // We can call faceLandmarker.detect as many times as we like with
            // different image data each time. This returns a promise
            // which we wait to complete and then call a function to
            // print out the results of the prediction.
            const faceLandmarkerResult = faceLandmarker.detect(event.target);
            const canvas = document.createElement("canvas");
            canvas.setAttribute("class", "canvas");
            canvas.setAttribute("width", event.target.naturalWidth + "px");
            canvas.setAttribute("height", event.target.naturalHeight + "px");
            canvas.style.left = "0px";
            canvas.style.top = "0px";
            canvas.style.width = `${event.target.width}px`;
            canvas.style.height = `${event.target.height}px`;

            event.target.parentNode.appendChild(canvas);
            const ctx = canvas.getContext("2d");
            const drawingUtils = new DrawingUtils(ctx);
            for (const landmarks of faceLandmarkerResult.faceLandmarks) {
                drawingUtils.drawConnectors(
                    landmarks,
                    FaceLandmarker.FACE_LANDMARKS_TESSELATION,
                    { color: "#C0C0C070", lineWidth: 1 }
                );
                drawingUtils.drawConnectors(
                    landmarks,
                    FaceLandmarker.FACE_LANDMARKS_RIGHT_EYE,
                    { color: "#FF3030" }
                );
                drawingUtils.drawConnectors(
                    landmarks,
                    FaceLandmarker.FACE_LANDMARKS_RIGHT_EYEBROW,
                    { color: "#FF3030" }
                );
                drawingUtils.drawConnectors(
                    landmarks,
                    FaceLandmarker.FACE_LANDMARKS_LEFT_EYE,
                    { color: "#30FF30" }
                );
                drawingUtils.drawConnectors(
                    landmarks,
                    FaceLandmarker.FACE_LANDMARKS_LEFT_EYEBROW,
                    { color: "#30FF30" }
                );
                drawingUtils.drawConnectors(
                    landmarks,
                    FaceLandmarker.FACE_LANDMARKS_FACE_OVAL,
                    { color: "#E0E0E0" }
                );
                drawingUtils.drawConnectors(landmarks, FaceLandmarker.FACE_LANDMARKS_LIPS, {
                    color: "#E0E0E0"
                });
                drawingUtils.drawConnectors(
                    landmarks,
                    FaceLandmarker.FACE_LANDMARKS_RIGHT_IRIS,
                    { color: "#FF3030" }
                );
                drawingUtils.drawConnectors(
                    landmarks,
                    FaceLandmarker.FACE_LANDMARKS_LEFT_IRIS,
                    { color: "#30FF30" }
                );
            }
            drawBlendShapes(imageBlendShapes, faceLandmarkerResult.faceBlendshapes);
        }

        /********************************************************************
        // Demo 2: Continuously grab image from webcam stream and detect it.
        ********************************************************************/

        const video = document.getElementById("webcam");
        const canvasElement = document.getElementById(
            "output_canvas"
        );
        const gestureOutput = document.getElementById("gesture_output");

        const canvasCtx = canvasElement.getContext("2d");

        // Check if webcam access is supported.
        function hasGetUserMedia() {
            return !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia);
        }

        // If webcam supported, add event listener to button for when user
        // wants to activate it.
        if (hasGetUserMedia()) {
            enableWebcamButton = document.getElementById(
                "webcamButton");
            enableWebcamButton.addEventListener("click", enableCam);
        } else {
            console.warn("getUserMedia() is not supported by your browser");
        }

        // Enable the live webcam view and start detection.
        function enableCam(event) {
            if (!faceLandmarker) {
                console.log("Wait! faceLandmarker not loaded yet.");
                return;
            }

            if (webcamRunning === true) {
                webcamRunning = false;
                enableWebcamButton.innerText = "ENABLE PREDICTIONS";
            } else {
                webcamRunning = true;
                enableWebcamButton.innerText = "DISABLE PREDICTIONS";
            }

            // getUsermedia parameters.
            const constraints = {
                video: true
            };

            // Activate the webcam stream.
            navigator.mediaDevices.getUserMedia(constraints).then((stream) => {
                video.srcObject = stream;
                video.addEventListener("loadeddata", predictWebcam);
            });
        }

        let lastVideoTime = -1;
        let gazeResults = undefined;
        let gestureResults = undefined;
        const drawingUtils = new DrawingUtils(canvasCtx);
        async function predictWebcam() {
            const radio = video.videoHeight / video.videoWidth;
            video.style.width = videoWidth + "px";
            video.style.height = videoWidth * radio + "px";
            canvasElement.style.width = videoWidth + "px";
            canvasElement.style.height = videoWidth * radio + "px";
            canvasElement.width = video.videoWidth;
            canvasElement.height = video.videoHeight;
            // Now let's start detecting the stream.
            if (runningMode === "IMAGE") {
                runningMode = "VIDEO";
                await faceLandmarker.setOptions({ runningMode: runningMode });
            }
            let startTimeMs = performance.now();
            if (lastVideoTime !== video.currentTime) {
                lastVideoTime = video.currentTime;
                gazeResults = faceLandmarker.detectForVideo(video, startTimeMs);
                gestureResults = gestureRecognizer.recognizeForVideo(video, startTimeMs);
            }

            if (gestureResults.gestures.length > 0) {
                // gestureOutput.style.display = "block";
                // gestureOutput.style.width = videoWidth;
                const categoryName = gestureResults.gestures[0][0].categoryName;
                const categoryScore = parseFloat(gestureResults.gestures[0][0].score * 100).toFixed(2);
                const handedness = gestureResults.handednesses[0][0].displayName;
                gestureOutput.innerText = `GestureRecognizer: ${categoryName}\n Confidence: ${categoryScore} %\n Handedness: ${handedness}`;
            }

            if (gazeResults.faceLandmarks) {
                for (const landmarks of gazeResults.faceLandmarks) {
                    drawingUtils.drawConnectors(
                        landmarks,
                        FaceLandmarker.FACE_LANDMARKS_TESSELATION,
                        { color: "#C0C0C070", lineWidth: 1 }
                    );
                    drawingUtils.drawConnectors(
                        landmarks,
                        FaceLandmarker.FACE_LANDMARKS_RIGHT_EYE,
                        { color: "#FF3030" }
                    );
                    drawingUtils.drawConnectors(
                        landmarks,
                        FaceLandmarker.FACE_LANDMARKS_RIGHT_EYEBROW,
                        { color: "#FF3030" }
                    );
                    drawingUtils.drawConnectors(
                        landmarks,
                        FaceLandmarker.FACE_LANDMARKS_LEFT_EYE,
                        { color: "#30FF30" }
                    );
                    drawingUtils.drawConnectors(
                        landmarks,
                        FaceLandmarker.FACE_LANDMARKS_LEFT_EYEBROW,
                        { color: "#30FF30" }
                    );
                    drawingUtils.drawConnectors(
                        landmarks,
                        FaceLandmarker.FACE_LANDMARKS_FACE_OVAL,
                        { color: "#E0E0E0" }
                    );
                    drawingUtils.drawConnectors(
                        landmarks,
                        FaceLandmarker.FACE_LANDMARKS_LIPS,
                        { color: "#E0E0E0" }
                    );
                    drawingUtils.drawConnectors(
                        landmarks,
                        FaceLandmarker.FACE_LANDMARKS_RIGHT_IRIS,
                        { color: "#FF3030" }
                    );
                    drawingUtils.drawConnectors(
                        landmarks,
                        FaceLandmarker.FACE_LANDMARKS_LEFT_IRIS,
                        { color: "#30FF30" }
                    );
                }
            }
            drawBlendShapes(videoBlendShapes, gazeResults.faceBlendshapes);

            // Call this function again to keep predicting when the browser is ready.
            if (webcamRunning === true) {
                window.requestAnimationFrame(predictWebcam);
            }
        }

        function checkIsVideoPlaying() {
            if (!window.YT && !window.YT.PlayerState) {
                throw new Error('YouTube Embed API has not loaded is not found')
            }
            return player.getPlayerState() === YT.PlayerState.PLAYING
        }
        

        const getAttributeScoreMap = (data) => {
            return data.categories.reduce((map, { categoryName, score }) => {
                if (!TARGET_ATTRIBUTES.has(categoryName)) {
                    return map
                }
                map[categoryName] = score;
                return map;
            }, {})
        }
        const checkIsAnyAttributePairOutsideThreshold = (attributeScoreMap) => {
            const { eyeLookDownLeft,
                eyeLookDownRight,
                eyeLookInLeft,
                eyeLookInRight,
                eyeLookOutLeft,
                eyeLookOutRight,
                eyeLookUpLeft,
                eyeLookUpRight } = attributeScoreMap
            // user looking left of camera outside threshold
            if (eyeLookInRight > PLAYBACK_THRESHOLD && eyeLookOutLeft > PLAYBACK_THRESHOLD) {
                console.log('left threshold exceeded')
                return true
            }
            // user looking right of camera outside threshold
            if (eyeLookInLeft > PLAYBACK_THRESHOLD && eyeLookOutRight > PLAYBACK_THRESHOLD) {
                console.log('right threshold exceeded')

                return true
            }
            // user looking below camera outside threshold
            if (eyeLookDownLeft > PLAYBACK_THRESHOLD && eyeLookDownRight > PLAYBACK_THRESHOLD) {
                console.log('below threshold exceeded')
                return true
            }
            // user looking above camera outside threshold

            if (eyeLookUpLeft > PLAYBACK_THRESHOLD && eyeLookUpRight > PLAYBACK_THRESHOLD) {
                console.log('above threshold exceeded')

                return true
            }
            return false
        }

        function setPlayback(attributeScoreMap) {
            if(!window.userHasInteractedWithVideo) {
                console.log('User needs to initiate playback first')
                return
            }
            const isAnyAttributePairOutsideThreshold = checkIsAnyAttributePairOutsideThreshold(attributeScoreMap)
            const isVideoPlaying = checkIsVideoPlaying()
            // video is playing and threshold is exceeded
            // pause video
            if (isVideoPlaying && isAnyAttributePairOutsideThreshold) {
                player.pauseVideo()
            }
            // video playing and threshold not exceeded
            // don't do anything
            // video is paused and threshold is exceeded
            // don't do anything
            // video paused and threshold is not exceeded
            // play video
            if (!isVideoPlaying && !isAnyAttributePairOutsideThreshold) {
                player.playVideo()
            }
        }

        function drawBlendShapes(el, blendShapes) {
            if (!blendShapes.length) {
                return;
            }

            // console.log(blendShapes[0]);
            const attributeScoreMap = getAttributeScoreMap(blendShapes[0])
            setPlayback(attributeScoreMap)

            let htmlMaker = "";
            blendShapes[0].categories.map((shape) => {
                const { categoryName, displayName } = shape
                if (!TARGET_ATTRIBUTES.has(shape.displayName) && !TARGET_ATTRIBUTES.has(shape.categoryName)) {
                    return
                }
                
                htmlMaker += `
      <li class="blend-shapes-item">
        <span class="blend-shapes-label">${shape.displayName || shape.categoryName
                    }</span>
        <span class="blend-shapes-value" style="width: calc(${+shape.score * 100
                    }% - 120px)">${(+shape.score).toFixed(4)}</span>
      </li>
    `;
            });

            el.innerHTML = htmlMaker;
        }
    </script>
    <script type="module">
        
    </script>
</body>

</html>
